{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ae000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version mise a jour en juin 2024 pour une nouvelle structure de fichier .pkl\n",
    "# et pour travailler avec des dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34438e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from matplotlib.backend_bases import MouseButton\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import nitime\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from pathlib import Path\n",
    "import netCDF4\n",
    "\n",
    "#from statistics import linear_regression\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79b1ed",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a908a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gety_OLD(depth,signal,xp):\n",
    "    #deprecated\n",
    "    ind = [np.argwhere(depth == xp[i])[0][0] for i in range(len(xp))]\n",
    "    return list(signal[ind])\n",
    "\n",
    "def gety(depth,signal,xp):\n",
    "    return np.interp(xp,depth,signal)\n",
    "\n",
    "def getlinks(ax,xp1,xp2,yp1,yp2):\n",
    "    \n",
    "    combinedTransform = ax[1].transData + ax[0].transData.inverted()\n",
    "\n",
    "    \n",
    "    xyp1 = [combinedTransform.inverted().transform(bob) for bob in zip(xp1,yp1)]\n",
    "    xp1_on_ax2 = [bob[0] for bob in xyp1]\n",
    "    yp1_on_ax2 = [bob[1] for bob in xyp1]\n",
    "        \n",
    "    xp_links = np.full(len(xp1)+2*len(xp2),np.nan)\n",
    "    yp_links = xp_links.copy()\n",
    "    \n",
    "    xp_links[::3] = xp1_on_ax2.copy()\n",
    "    xp_links[1::3] = xp2.copy()\n",
    "    \n",
    "    yp_links[::3] = yp1_on_ax2.copy()\n",
    "    yp_links[1::3] = yp2.copy()\n",
    "\n",
    "    return xp_links,yp_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3e77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a7bf835",
   "metadata": {},
   "source": [
    "# basic file handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dic_file(filename):\n",
    "    \n",
    "    with open(filename, 'rb') as fp:\n",
    "        dic = pickle.load(fp)\n",
    "        \n",
    "    return dic\n",
    "\n",
    "def write_dic_file(dic,filename):\n",
    "    \n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(dic, fp)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54622c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_marked_points(aligfile):\n",
    "        # convert the tiepoints stored in the dictionary to the xp1 and xp2 lists\n",
    "        \n",
    "        new_dic = load_dic_file(aligfile)\n",
    "        \n",
    "        xp1_dic = {}\n",
    "        xp2_dic = {}\n",
    "        \n",
    "        for profile_key in new_dic['tiepoints'].keys():\n",
    "        \n",
    "            tiepoints = new_dic['tiepoints'][profile_key]\n",
    "            xp1 = [bob['profile_depth'] for bob in tiepoints]\n",
    "            xp2 = [bob['ref_depth'] for bob in tiepoints]\n",
    "        \n",
    "            if len(xp2)>0:\n",
    "                # sort points\n",
    "                xp1,xp2 = zip(*sorted(zip(xp1,xp2)))\n",
    "\n",
    "            xp1_dic[profile_key] = xp1\n",
    "            xp2_dic[profile_key] = xp2\n",
    "        \n",
    "        return xp1_dic,xp2_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_marked_points_old(aligfile):\n",
    "    \n",
    "    # load depth dictionary from alignment file\n",
    "    \n",
    "    new_dic = load_dic_file(aligfile)\n",
    "    xp1_dic = {}\n",
    "    xp2_dic = {}\n",
    "    \n",
    "    for profile_key in new_dic['tiepoints'].keys():\n",
    "        xp1 = new_dic['tiepoints'][profile_key]['xp1']\n",
    "        xp2 = new_dic['tiepoints'][profile_key]['xp2']\n",
    "        \n",
    "        if len(xp2)>0:\n",
    "            # sort points\n",
    "            xp1,xp2 = zip(*sorted(zip(xp1,xp2)))\n",
    "\n",
    "        xp1_dic[profile_key] = xp1\n",
    "        xp2_dic[profile_key] = xp2\n",
    "    \n",
    "                \n",
    "    return xp1_dic,xp2_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_profiles_data(aligfile):\n",
    "    \n",
    "    full_dic = load_dic_file(aligfile)\n",
    "    \n",
    "    cores_dic = {key:value for key,value in full_dic['cores'].items() if key !='REF'}\n",
    "    ref_dic = full_dic['cores']['REF']\n",
    "    \n",
    "    return ref_dic,cores_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb56a5c",
   "metadata": {},
   "source": [
    "## trench setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96400cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_depth_scale(depthdictionary,dz):\n",
    "    \n",
    "    dz = 3\n",
    "    zmin = min([min(value) for key,value in depthdictionary.items()])\n",
    "    zmax = max([max(value) for key,value in depthdictionary.items()])\n",
    "    depth_scale = np.arange(zmin,zmax,dz)\n",
    "    \n",
    "    return depth_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a614ebb2",
   "metadata": {},
   "source": [
    "### exploiting alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14232614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert an xlsx file to a dictionary\n",
    "\n",
    "def load_xlsdata(datafile):\n",
    "    xls = pd.ExcelFile(datafile)\n",
    "\n",
    "    # each sheet corresponds to a pit\n",
    "\n",
    "    core_names = xls.sheet_names[:]\n",
    "    \n",
    "    new_dic ={}\n",
    "    \n",
    "    for i,lab in enumerate(core_names):\n",
    "    \n",
    "        df = pd.read_excel(datafile,sheet_name=i,skiprows = 0, header = None).replace('n.a.', np.nan)\n",
    "    \n",
    "        #sample_date_timestamp = df.iloc[0,3]\n",
    "        #sample_date = sample_date_timestamp.date()\n",
    "        sample_date = datetime.date(2000,1,1)\n",
    "    \n",
    "        core_depth = df.to_numpy()[1:,0].astype(None)\n",
    "    \n",
    "        #print(core_depth)\n",
    "    \n",
    "        new_dic[lab] = {}\n",
    "        \n",
    "        for i in range(1,len(df.T)):\n",
    "            chem_name = df.to_numpy()[0,i]\n",
    "            chem_profile = df.to_numpy()[1:,i].astype(None)\n",
    "            new_dic[lab][chem_name] = {}\n",
    "\n",
    "            new_dic[lab][chem_name]['depth'] = core_depth.copy()\n",
    "\n",
    "            new_dic[lab][chem_name]['data'] = chem_profile.copy()\n",
    "            \n",
    "    return new_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d5a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9968f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae499d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecbdf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fa4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_sqz_str(depth1,xp1,xp2):\n",
    "    # JUNE2024: we still need to improve this function for coinciding xp1 points (hiatus)\n",
    "    # roughly the same as np.interp but no error if xp1 is empty\n",
    "    depth_out = np.full(depth1.shape,np.nan)\n",
    "    if len(xp2)>0:\n",
    "        # sort points\n",
    "        xp1,xp2 = zip(*sorted(zip(xp1,xp2)))\n",
    "        depth_out = np.interp(depth1,xp1[:len(xp2)],xp2)\n",
    "    return depth_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6125d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9f64714",
   "metadata": {},
   "source": [
    "### if we want to visualize the stretch applied on each profile\n",
    "deprecated: think about what we need now for depth profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c345c0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "def load_stretch_array(aligfile,vertical_scale = None,labels=None):\n",
    "    \n",
    "    # create an array with \n",
    "    \n",
    "    ref_dic,cores_dic = load_profiles_data(aligfile)\n",
    "    \n",
    "    xp1_dic,xp2_dic = load_marked_points(aligfile)\n",
    "    \n",
    "    if labels is None: \n",
    "        labels = cores_dic.keys()\n",
    "    \n",
    "    if vertical_scale is None:\n",
    "        return 'Please specify vertical scale!'\n",
    "        #vertical_scale = ref_dic['depth'].copy()\n",
    "        \n",
    "        \n",
    "    npits = len(labels)\n",
    "    \n",
    "    #data = chem_profiles[species]\n",
    "    \n",
    "    out = {}\n",
    "    \n",
    "    for i,pitlab in enumerate(labels):\n",
    "        if pitlab in cores_dic.keys():\n",
    "            \n",
    "            depth_new = depth_sqz_str(cores_dic[pitlab]['depth'],xp1_dic[pitlab],xp2_dic[pitlab])\n",
    "\n",
    "            gradient = np.diff(depth_new)/np.diff(cores_dic[pitlab]['depth'])\n",
    "    \n",
    "            gradient_out = np.interp(vertical_scale,depth_new[:-1],gradient,left=np.nan,right=np.nan)\n",
    "        \n",
    "            out[:,i] = gradient_out\n",
    "\n",
    "                \n",
    "    df = pd.DataFrame(data=out)\n",
    "    df.index = vertical_scale.copy()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3defced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5280e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO JUNE 2024: merge the following into a single function with a master function\n",
    "## wrapper1: from the alignment file, specifying a species\n",
    "## wrapper2: from the alignment file and the datafile, specifying a species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alig_array(aligfile,species,vertical_scale= None,labels = None):\n",
    "    \n",
    "    # create an array with \n",
    "    \n",
    "    ref_dic,cores_dic = load_profiles_data(aligfile)\n",
    "    \n",
    "    xp1_dic,xp2_dic = load_marked_points(aligfile)\n",
    "\n",
    "    \n",
    "    if vertical_scale is None:\n",
    "        vertical_scale = ref_dic[species]['depth'].copy()\n",
    "             \n",
    "    if labels is None: \n",
    "        labels = cores_dic.keys()\n",
    "        \n",
    "    npits = len(labels)\n",
    "    \n",
    "    #data = chem_profiles[species]\n",
    "    \n",
    "    out = {}\n",
    "        \n",
    "    for profile in labels:\n",
    "        if species in cores_dic[profile] and profile in xp1_dic.keys():\n",
    "            \n",
    "            depth_new = depth_sqz_str(cores_dic[profile][species]['depth'],xp1_dic[profile],xp2_dic[profile])\n",
    "    \n",
    "            signal_new = np.interp(vertical_scale,depth_new,cores_dic[profile][species]['data']\n",
    "                                   ,left=np.nan,right=np.nan)\n",
    "    \n",
    "            out[profile] = signal_new.copy()\n",
    "    \n",
    "        else:\n",
    "            print('missing data or tiepoints for ',profile)\n",
    "            out[profile] = np.full(len(vertical_scale),np.nan)\n",
    "            \n",
    "\n",
    "    df = pd.DataFrame(data=out)\n",
    "    df.index = vertical_scale.copy()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97243c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aligned_datafile(aligfile,datafile,species,vertical_scale= None,labels = None):\n",
    "    \n",
    "    ref_dic,cores_dic = load_profiles_data(aligfile)\n",
    "    \n",
    "    xp1_dic,xp2_dic = load_marked_points(aligfile)\n",
    "\n",
    "    \n",
    "    if vertical_scale is None:\n",
    "        vertical_scale = ref_dic[species]['depth'].copy()\n",
    "             \n",
    "    if labels is None: \n",
    "        labels = cores_dic.keys()\n",
    "        \n",
    "    npits = len(labels)\n",
    "    \n",
    "    #data = chem_profiles[species]\n",
    "    \n",
    "    datadic = load_xlsdata(datafile)\n",
    "    \n",
    "    depth_profiles2 = {key:datadic[key][species]['depth'] for key in datadic.keys()}\n",
    "    data2 = {key:datadic[key][species]['data'] for key in datadic.keys()}\n",
    "    \n",
    "    out = {}\n",
    "        \n",
    "    for profile in labels:\n",
    "        if profile in depth_profiles2.keys() and profile in xp1_dic.keys():\n",
    "            \n",
    "            depth_new = depth_sqz_str(depth_profiles2[profile],xp1_dic[profile],xp2_dic[profile])\n",
    "\n",
    "    \n",
    "            signal_new = np.interp(vertical_scale,depth_new,data2[profile],left=np.nan,right=np.nan)\n",
    "    \n",
    "            out[profile] = signal_new.copy()\n",
    "    \n",
    "        else:\n",
    "            out[:,i] = np.full(len(vertical_scale),np.nan)\n",
    "            \n",
    "\n",
    "    df = pd.DataFrame(data=out)\n",
    "    df.index = vertical_scale.copy()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb9469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad38f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbc1444d",
   "metadata": {},
   "source": [
    "### when we want to load data on a common vertical scale without any alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e500a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_interp_datafile(datafile,species,vertical_scale = None,labels = None):\n",
    "    datadic = load_xlsdata(datafile)\n",
    "    return load_interp_dic(datadic,species,vertical_scale,labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2783f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_interp_dic(datadic,species,vertical_scale = None,labels = None):  \n",
    "    \n",
    "    depth_profiles2 = {key:datadic[key][species]['depth'] for key in datadic.keys()}\n",
    "    data = {key:datadic[key][species]['data'] for key in datadic.keys()}\n",
    "    \n",
    "             \n",
    "    if labels is None: \n",
    "        labels = depth_profiles2.keys()\n",
    "        \n",
    "    if vertical_scale is None:\n",
    "        vertical_scale = depth_profiles2[list(labels)[0]].copy()\n",
    "    \n",
    "    out = {}\n",
    "        \n",
    "    for profile in labels:         \n",
    "    \n",
    "        signal_new = np.interp(vertical_scale,depth_profiles2[profile],data[profile],left=np.nan,right=np.nan)\n",
    "    \n",
    "        out[profile] = signal_new.copy()            \n",
    "\n",
    "    df = pd.DataFrame(data=out)\n",
    "    df.index = vertical_scale.copy()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97e809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bdcbab8",
   "metadata": {},
   "source": [
    "# power spectral densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtm_psd(signal_in,fs,detrend = True):\n",
    "    \n",
    "    signal = signal_in.copy()\n",
    "    # linear detrending\n",
    "    if detrend:\n",
    "        xs = np.array(range(len(signal)))\n",
    "        a,b = scipy.stats.linregress(xs, signal, alternative='two-sided')[:2]\n",
    "        trend = a*xs+b\n",
    "        signal -= trend\n",
    "    \n",
    "    ff,pxx = nitime.algorithms.multi_taper_psd(\n",
    "    signal,NW = 2.5,adaptive=False, jackknife=False, Fs = fs, sides = 'onesided'\n",
    "    )[:2]\n",
    "    return ff,pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSD_MSMn(data_int,fs):\n",
    "    \n",
    "    # takes an input a data array and returns the mean PSD, PSD of mean and PSD's of columns\n",
    "    \n",
    "    # data_int is assumed to be already equaly sampled AND filled\n",
    "    \n",
    "    # Mean of power spectrum\n",
    "    # S power spectrum of mean\n",
    "    # Mn = M/n Mean power spectrum divided by number of arrays\n",
    "    \n",
    "    npits = data_int.shape[1]\n",
    "        \n",
    "    datamean = mean_signal(data_int)\n",
    "    \n",
    "    freq0,pxx0 = mtm_psd(datamean,fs)\n",
    "    \n",
    "    PXX = np.full([freq0.size,npits],np.nan)\n",
    "    for j in range(npits):\n",
    "        PXX[:,j] = mtm_psd(data_int[:,j],fs)[1]\n",
    "        \n",
    "    PXXmean = np.mean(PXX,axis=1)\n",
    "    \n",
    "    return freq0,pxx0,PXXmean,PXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SNR(pxx0,PXXmean,PXX):\n",
    "    npits = PXX.shape[1]\n",
    "    \n",
    "    M = PXXmean\n",
    "    S = pxx0\n",
    "\n",
    "    C = S-M/npits\n",
    "    N = (M-S)\n",
    "    \n",
    "    SNR = np.maximum(C/N,np.full(C.shape,0)) # reject negative values\n",
    "    \n",
    "    return C,N,SNR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
